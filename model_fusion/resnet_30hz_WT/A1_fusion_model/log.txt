单特征卷积后输入模型




====--------------
Wavelet 128,128
======================
2025-02-13 15:58:38.729934: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-13 15:58:39.252713: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
当前日期和时间: 2025-02-13 15:58:40.304308
  1_using cuda:0 device.

查看dataset 单条数据
  sample1 shape:((128, 128), <class 'numpy.ndarray'>) , Label:(1, <class 'numpy.int64'>)
  total data:5000,epochs:20,batch_size:32
  1 epoch has 157 steps
查看train_loader 容器数据
  total data 4000
  batch_size: 32
  Number of batches: 125
  type of batches: <class 'torch.utils.data.dataloader.DataLoader'>
input shape: torch.Size([32, 1, 128, 128])
input type: torch.FloatTensor
lable shape: torch.Size([32])
lable type: torch.LongTensor

自定义模型
++++++   start train  ++++++
+++++++  ----------  +++++++
[1 epoch, 41 step]:
accuracy: 0.7355182926829268 , loss: 0.6454307807654869
[1 epoch, 82 step]:
accuracy: 0.9573170731707317 , loss: 0.1337171780944961
[1 epoch, 123 step]:
accuracy: 0.9679878048780488 , loss: 0.09346311448550806
---------------- current_learn_rate ----------------- : 0.000100000000000
[2 epoch, 41 step]:
accuracy: 0.9861918604651163 , loss: 0.040532865141313976
[2 epoch, 82 step]:
accuracy: 0.9923780487804879 , loss: 0.02162232198866039
[2 epoch, 123 step]:
accuracy: 0.9992378048780488 , loss: 0.009443396143047365
---------------- current_learn_rate ----------------- : 0.000100000000000
[3 epoch, 41 step]:
accuracy: 0.9992732558139535 , loss: 0.005855505952395771
[3 epoch, 82 step]:
accuracy: 1.0 , loss: 0.002897799077511924
[3 epoch, 123 step]:
accuracy: 0.9992378048780488 , loss: 0.0038098806384723725
---------------- current_learn_rate ----------------- : 0.000100000000000
[4 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0021291997960893572
[4 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0011132305974947152
[4 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0009413277070185669
---------------- current_learn_rate ----------------- : 0.000100000000000
[5 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0008848619934103293
[5 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0006095547635085517
[5 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0006122164177657218
---------------- current_learn_rate ----------------- : 0.000100000000000
[6 epoch, 41 step]:
accuracy: 1.0 , loss: 0.000611126744798839
[6 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00044433795705028787
[6 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00046990033687751106
---------------- current_learn_rate ----------------- : 0.000100000000000
[7 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0004754045097265256
[7 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0003526746495925004
[7 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00037811399066945675
---------------- current_learn_rate ----------------- : 0.000100000000000
[8 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0003857566973637426
[8 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00028975711313428403
[8 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00031294652226057315
---------------- current_learn_rate ----------------- : 0.000100000000000
[9 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0003213245026261841
[9 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00024351168785204474
[9 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0002642504653677617
---------------- current_learn_rate ----------------- : 0.000100000000000
[10 epoch, 41 step]:
accuracy: 1.0 , loss: 0.000272836743001457
[10 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00020807313469448695
[10 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00022642053422381784
---------------- current_learn_rate ----------------- : 0.000100000000000
[11 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00023477093063553272
[11 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00018001101480189302
[11 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00019645883287189574
---------------- current_learn_rate ----------------- : 0.000100000000000
[12 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00020432161936031017
[12 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0001573485240486462
[12 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00017204897990379277
---------------- current_learn_rate ----------------- : 0.000100000000000
[13 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00018102911781170405
[13 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00014278324111151826
[13 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00015904408472834338
---------------- current_learn_rate ----------------- : 0.000010000000000
[14 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0001783964236404622
[14 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00014077234362314524
[14 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00015716949600595752
---------------- current_learn_rate ----------------- : 0.000010000000000
[15 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00017576811953359738
[15 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00013877627116460467
[15 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00015519578904254225
---------------- current_learn_rate ----------------- : 0.000010000000000
[16 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00017310408816783598
[16 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00013670951890029445
[16 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0001530973443040261
---------------- current_learn_rate ----------------- : 0.000010000000000
[17 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00017037815623774716
[17 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00013461094186357337
[17 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00015087512558859933
---------------- current_learn_rate ----------------- : 0.000010000000000
[18 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00016757033092023736
[18 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00013244575902495942
[18 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00014854038906888468
---------------- current_learn_rate ----------------- : 0.000010000000000
[19 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00016465932436048893
[19 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00013020472494933594
[19 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00014608443394181227
---------------- current_learn_rate ----------------- : 0.000010000000000
[20 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00016168179354281165
[20 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00012790870761552757
[20 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00014356795305147676
---------------- current_learn_rate ----------------- : 0.000010000000000
total_time:0.5618257840474447min
Finished Training
++++++++  start test  +++++++
++++++++  ----------  +++++++
Accuracy of the network on the 998/1000 tests: 99.80 %
[188.0, 207.0, 189.0, 201.0, 215.0]

Accuracy of normal : 100.00 %
Accuracy of broken : 99.52 %
Accuracy of missing_tooth : 99.47 %
Accuracy of root_crack : 100.00 %
Accuracy of  wear : 100.00 %








--===============
STFT 17,97 
--=================
2025-02-13 16:05:01.343068: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-13 16:05:01.866864: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
当前日期和时间: 2025-02-13 16:05:02.914792
  1_using cuda:0 device.
查看dataset 单条数据
  sample1 shape:((17, 97), <class 'numpy.ndarray'>) , Label:(1, <class 'numpy.int64'>)
  total data:5000,epochs:20,batch_size:32
  1 epoch has 157 steps
查看train_loader 容器数据
  total data 4000
  batch_size: 32
  Number of batches: 125
  type of batches: <class 'torch.utils.data.dataloader.DataLoader'>
input shape: torch.Size([32, 1, 17, 97])
input type: torch.FloatTensor
lable shape: torch.Size([32])
lable type: torch.LongTensor

查看dataset 单条数据
  sample1 shape:((128, 128), <class 'numpy.ndarray'>) , Label:(1, <class 'numpy.int64'>)
  total data:5000,epochs:20,batch_size:32
  1 epoch has 157 steps
查看train_loader 容器数据
  total data 4000
  batch_size: 32
  Number of batches: 125
  type of batches: <class 'torch.utils.data.dataloader.DataLoader'>
input shape: torch.Size([32, 1, 128, 128])
input type: torch.FloatTensor
lable shape: torch.Size([32])
lable type: torch.LongTensor

自定义模型
++++++   start train  ++++++
+++++++  ----------  +++++++
[1 epoch, 41 step]:
accuracy: 0.711890243902439 , loss: 0.7048051640754793
[1 epoch, 82 step]:
accuracy: 0.9314024390243902 , loss: 0.22333361053975617
[1 epoch, 123 step]:
accuracy: 0.9474085365853658 , loss: 0.1572726314614822
---------------- current_learn_rate ----------------- : 0.000100000000000
[2 epoch, 41 step]:
accuracy: 0.9731104651162791 , loss: 0.08049626990289586
[2 epoch, 82 step]:
accuracy: 0.9855182926829268 , loss: 0.05045949501871336
[2 epoch, 123 step]:
accuracy: 0.9870426829268293 , loss: 0.047685748511334745
---------------- current_learn_rate ----------------- : 0.000100000000000
[3 epoch, 41 step]:
accuracy: 0.9934593023255814 , loss: 0.022030382979343215
[3 epoch, 82 step]:
accuracy: 0.9984756097560976 , loss: 0.009412318712282108
[3 epoch, 123 step]:
accuracy: 0.9969512195121951 , loss: 0.012501089129506088
---------------- current_learn_rate ----------------- : 0.000100000000000
[4 epoch, 41 step]:
accuracy: 0.9978197674418605 , loss: 0.011693703751761193
[4 epoch, 82 step]:
accuracy: 1.0 , loss: 0.002950563664099474
[4 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0026223902085159975
---------------- current_learn_rate ----------------- : 0.000100000000000
[5 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0014928807859399878
[5 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0011119936208138469
[5 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0009380379608667614
---------------- current_learn_rate ----------------- : 0.000100000000000
[6 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0007975691526265042
[6 epoch, 82 step]:
accuracy: 1.0 , loss: 0.000646293688233283
[6 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0006328743033142328
---------------- current_learn_rate ----------------- : 0.000100000000000
[7 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0005860274906764262
[7 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0004899058403680101
[7 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00048777858638658937
---------------- current_learn_rate ----------------- : 0.000100000000000
[8 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0004640491122078923
[8 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00039073354820152973
[8 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00039379308642620764
---------------- current_learn_rate ----------------- : 0.000100000000000
[9 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0003808845542995941
[9 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0003214479699481006
[9 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0003268722486121455
---------------- current_learn_rate ----------------- : 0.000100000000000
[10 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0003199233924089817
[10 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00027005728611029776
[10 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0002769031858273282
---------------- current_learn_rate ----------------- : 0.000100000000000
[11 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0002732702198001079
[11 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00023053487938141633
[11 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00023810759659859398
---------------- current_learn_rate ----------------- : 0.000100000000000
[12 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00023649794847431887
[12 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00019928464657490756
[12 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00020704360745517854
---------------- current_learn_rate ----------------- : 0.000100000000000
[13 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00021021621370625614
[13 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00017714111553930972
[13 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00019130901628381164
---------------- current_learn_rate ----------------- : 0.000010000000000
[14 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00020700212225187341
[14 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00017487839760156577
[14 epoch, 123 step]:
accuracy: 1.0 , loss: 0.0001888984318988727
---------------- current_learn_rate ----------------- : 0.000010000000000
[15 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00020373412926124817
[15 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00017248229166242954
[15 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00018637355819142924
---------------- current_learn_rate ----------------- : 0.000010000000000
[16 epoch, 41 step]:
accuracy: 1.0 , loss: 0.0002003932980786464
[16 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0001699941281780101
[16 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00018372565859974156
---------------- current_learn_rate ----------------- : 0.000010000000000
[17 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00019698788141462635
[17 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00016736828707152886
[17 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00018092623648088902
---------------- current_learn_rate ----------------- : 0.000010000000000
[18 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00019352889027753162
[18 epoch, 82 step]:
accuracy: 1.0 , loss: 0.00016459443098183993
[18 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00017800442308326615
---------------- current_learn_rate ----------------- : 0.000010000000000
[19 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00019000803610940304
[19 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0001617548048493407
[19 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00017496295070641946
---------------- current_learn_rate ----------------- : 0.000010000000000
[20 epoch, 41 step]:
accuracy: 1.0 , loss: 0.00018640721064890032
[20 epoch, 82 step]:
accuracy: 1.0 , loss: 0.0001587714129816116
[20 epoch, 123 step]:
accuracy: 1.0 , loss: 0.00017180919450943404
---------------- current_learn_rate ----------------- : 0.000010000000000
total_time:0.4021425406138102min
Finished Training
++++++++  start test  +++++++
++++++++  ----------  +++++++
Accuracy of the network on the 996/1000 tests: 99.60 %
[188.0, 207.0, 189.0, 201.0, 215.0]

Accuracy of normal : 100.00 %
Accuracy of broken : 99.52 %
Accuracy of missing_tooth : 98.94 %
Accuracy of root_crack : 100.00 %
Accuracy of  wear : 99.53 %

当前日期和时间: 2025-02-17 00:23:38.869448
  1_using cuda:0 device.
查看dataset 单条数据
  sample1 shape:((128, 1536), <class 'numpy.ndarray'>) , Label:(1, <class 'numpy.int64'>)
  total data:5000,epochs:20,batch_size:32
  1 epoch has 157 steps
查看train_loader 容器数据
  total data 3008
  batch_size: 32
  Number of batches: 94
  type of batches: <class 'torch.utils.data.dataloader.DataLoader'>
input shape: torch.Size([32, 1, 128, 1536])
input type: torch.FloatTensor
lable shape: torch.Size([32])
lable type: torch.LongTensor

自定义模型
torch.Size([32, 1, 128, 1536])
++++++   start train  ++++++
+++++++  ----------  +++++++
[1 epoch, 31 step]:
accuracy: 0.7127016129032258 , loss: 0.7671137139681847
[1 epoch, 62 step]:
accuracy: 0.907258064516129 , loss: 0.25466658667691294
[1 epoch, 93 step]:
accuracy: 0.9516129032258065 , loss: 0.1582189940156475
---------------- current_learn_rate ----------------- : 0.000100000000000
[2 epoch, 31 step]:
accuracy: 0.9655511811023622 , loss: 0.09501971472655574
[2 epoch, 62 step]:
accuracy: 0.9828629032258065 , loss: 0.05630277028127063
[2 epoch, 93 step]:
accuracy: 0.9828629032258065 , loss: 0.05330055692203103
---------------- current_learn_rate ----------------- : 0.000100000000000
[3 epoch, 31 step]:
accuracy: 0.9960629921259843 , loss: 0.023186064866040985
[3 epoch, 62 step]:
accuracy: 0.9979838709677419 , loss: 0.014677159097646513
[3 epoch, 93 step]:
accuracy: 0.9979838709677419 , loss: 0.015120592005851289
---------------- current_learn_rate ----------------- : 0.000100000000000
[4 epoch, 31 step]:
accuracy: 0.9980314960629921 , loss: 0.010500517876578434
[4 epoch, 62 step]:
accuracy: 1.0 , loss: 0.005697483290737915
[4 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0029679424403565783
---------------- current_learn_rate ----------------- : 0.000100000000000
[5 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0030683364152097174
[5 epoch, 62 step]:
accuracy: 1.0 , loss: 0.002550378582635594
[5 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0015570013962250442
---------------- current_learn_rate ----------------- : 0.000100000000000
[6 epoch, 31 step]:
accuracy: 1.0 , loss: 0.001370923334522353
[6 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0014327514274496465
[6 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0009348333659281413
---------------- current_learn_rate ----------------- : 0.000100000000000
[7 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0009845557637632855
[7 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0009523967502548569
[7 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0006771950011757473
---------------- current_learn_rate ----------------- : 0.000100000000000
[8 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0007561031201358644
[8 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0007409398695604215
[8 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0005422372604727805
---------------- current_learn_rate ----------------- : 0.000100000000000
[9 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0006158119687179644
[9 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0006091344609646307
[9 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0004511030213419168
---------------- current_learn_rate ----------------- : 0.000100000000000
[10 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0005168153293197975
[10 epoch, 62 step]:
accuracy: 1.0 , loss: 0.000514518809899117
[10 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003837276669782436
---------------- current_learn_rate ----------------- : 0.000100000000000
[11 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0004423836376630671
[11 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0004420496463294952
[11 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003316705490672781
---------------- current_learn_rate ----------------- : 0.000100000000000
[12 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003841198434407312
[12 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00038497273306993226
[12 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002899945210365038
---------------- current_learn_rate ----------------- : 0.000100000000000
[13 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00034031263578893436
[13 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003412238119410411
[13 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002665328847210584
---------------- current_learn_rate ----------------- : 0.000010000000000
[14 epoch, 31 step]:
accuracy: 1.0 , loss: 0.000334937279647772
[14 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003371560059378915
[14 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002633270607123362
---------------- current_learn_rate ----------------- : 0.000010000000000
[15 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003296272217055723
[15 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003329898515197959
[15 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002600182948123303
---------------- current_learn_rate ----------------- : 0.000010000000000
[16 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003244219739328048
[16 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003286700082225575
[16 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00025660259017322754
---------------- current_learn_rate ----------------- : 0.000010000000000
[17 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003192657447559008
[17 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003241386727876811
[17 epoch, 93 step]:
accuracy: 1.0 , loss: 0.000253063753799295
---------------- current_learn_rate ----------------- : 0.000010000000000
[18 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00031411495729116723
[18 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003195517793140044
[18 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002493503153316617
---------------- current_learn_rate ----------------- : 0.000010000000000
[19 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003089087298459133
[19 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003147585910835093
[19 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002455175495161975
---------------- current_learn_rate ----------------- : 0.000010000000000
[20 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003037099060395943
[20 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003098101989317295
[20 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00024161685489103077
---------------- current_learn_rate ----------------- : 0.000010000000000
total_time:1.4796003103256226min
Finished Training
++++++++  start test  +++++++
++++++++  ----------  +++++++
Accuracy of the network on the 1989/2000 tests: 99.45 %
[382.0, 413.0, 383.0, 415.0, 407.0]

Accuracy of normal : 100.00 %
Accuracy of broken : 99.27 %
Accuracy of missing_tooth : 98.43 %
Accuracy of root_crack : 99.76 %
Accuracy of  wear : 99.75 %
(deeplearning) PS C:\Users\Q\Desktop\paper\paper\2024_11_SCI\experiments\fusion\resnet_30hz_WT> & C:/Users/Q/anaconda3/envs/deeplearning/python.exe c:/Users/Q/Desktop/paper/paper/2024_11_SCI/experiments/fusion/resnet_30hz_WT/A1_fusion_model/resnet50_vib_train_test1.py
2025-02-17 00:26:33.882686: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-17 00:26:34.947142: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
当前日期和时间: 2025-02-17 00:26:37.288202
  1_using cuda:0 device.
查看dataset 单条数据
  sample1 shape:((17, 97), <class 'numpy.ndarray'>) , Label:(1, <class 'numpy.int64'>)
  total data:5000,epochs:20,batch_size:32
  1 epoch has 157 steps
查看train_loader 容器数据
  total data 3008
  batch_size: 32
  Number of batches: 94
  type of batches: <class 'torch.utils.data.dataloader.DataLoader'>
input shape: torch.Size([32, 1, 17, 97])
input type: torch.FloatTensor
lable shape: torch.Size([32])
lable type: torch.LongTensor

自定义模型
torch.Size([32, 1, 17, 97])
++++++   start train  ++++++
+++++++  ----------  +++++++
[1 epoch, 31 step]:
accuracy: 0.7227822580645161 , loss: 0.6841217673593952
[1 epoch, 62 step]:
accuracy: 0.9768145161290323 , loss: 0.09942910252439399
[1 epoch, 93 step]:
accuracy: 0.9848790322580645 , loss: 0.06394960339211168
---------------- current_learn_rate ----------------- : 0.000100000000000
[2 epoch, 31 step]:
accuracy: 0.9862204724409449 , loss: 0.04819302948101634
[2 epoch, 62 step]:
accuracy: 0.9959677419354839 , loss: 0.024384606464375413
[2 epoch, 93 step]:
accuracy: 0.9969758064516129 , loss: 0.01685094915240282
---------------- current_learn_rate ----------------- : 0.000100000000000
[3 epoch, 31 step]:
accuracy: 0.9990157480314961 , loss: 0.008484967385283522
[3 epoch, 62 step]:
accuracy: 0.9959677419354839 , loss: 0.01406795318959461
[3 epoch, 93 step]:
accuracy: 0.998991935483871 , loss: 0.01271673466732365
---------------- current_learn_rate ----------------- : 0.000100000000000
[4 epoch, 31 step]:
accuracy: 0.9980314960629921 , loss: 0.012564929125214657
[4 epoch, 62 step]:
accuracy: 1.0 , loss: 0.005978959894198324
[4 epoch, 93 step]:
accuracy: 0.9979838709677419 , loss: 0.005452689953193429
---------------- current_learn_rate ----------------- : 0.000100000000000
[5 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0025216069357890275
[5 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0014240328849653803
[5 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0009563727493983724
---------------- current_learn_rate ----------------- : 0.000100000000000
[6 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0009182664484063524
[6 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0007668745862658045
[6 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0005508969622878208
---------------- current_learn_rate ----------------- : 0.000100000000000
[7 epoch, 31 step]:
accuracy: 1.0 , loss: 0.000658617693848247
[7 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0005416164823409711
[7 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00042481527752017664
---------------- current_learn_rate ----------------- : 0.000100000000000
[8 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0005174369770458959
[8 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0004384659555545377
[8 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00034797344250687127
---------------- current_learn_rate ----------------- : 0.000100000000000
[9 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0004264419173611508
[9 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00036755517418984504
[9 epoch, 93 step]:
accuracy: 1.0 , loss: 0.000293691074588306
---------------- current_learn_rate ----------------- : 0.000100000000000
[10 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003607645008859465
[10 epoch, 62 step]:
accuracy: 1.0 , loss: 0.000315112202154142
[10 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002524132881174615
---------------- current_learn_rate ----------------- : 0.000100000000000
[11 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003108853568612117
[11 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00027410508905191934
[11 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00022011507943745762
---------------- current_learn_rate ----------------- : 0.000100000000000
[12 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0002712961571476978
[12 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00024123603338187922
[12 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0001938322467697529
---------------- current_learn_rate ----------------- : 0.000100000000000
[13 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0002412113507518605
[13 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00021613047471375114
[13 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00018091248820118996
---------------- current_learn_rate ----------------- : 0.000010000000000
[14 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0002378922519358551
[14 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0002137137442684522
[14 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00017883432132469851
---------------- current_learn_rate ----------------- : 0.000010000000000
[15 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00023453519010687278
[15 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00021121606245757112
[15 epoch, 93 step]:
accuracy: 1.0 , loss: 0.000176692848570735
---------------- current_learn_rate ----------------- : 0.000010000000000
[16 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00023113414347115453
[16 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00020862989960381041
[16 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0001744626695712683
---------------- current_learn_rate ----------------- : 0.000010000000000
[17 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00022768791654192272
[17 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00020592666870441228
[17 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00017212854002155513
---------------- current_learn_rate ----------------- : 0.000010000000000
[18 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00022417248739305164
[18 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00020314131454083947
[18 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00016969838097500014
---------------- current_learn_rate ----------------- : 0.000010000000000
[19 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00022060245546820243
[19 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0002003121985434254
[19 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00016722108757089553
---------------- current_learn_rate ----------------- : 0.000010000000000
[20 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00021696822190161555
[20 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0001973729825206852
[20 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0001646717327305176
---------------- current_learn_rate ----------------- : 0.000010000000000
total_time:1.0581680536270142min
Finished Training
++++++++  start test  +++++++
++++++++  ----------  +++++++
Accuracy of the network on the 1998/2000 tests: 99.90 %
[382.0, 413.0, 383.0, 415.0, 407.0]

Accuracy of normal : 100.00 %
Accuracy of broken : 100.00 %
Accuracy of missing_tooth : 99.48 %
Accuracy of root_crack : 100.00 %
Accuracy of  wear : 100.00 %




当前日期和时间: 2025-02-17 17:47:24.811583
  1_using cuda:0 device.
查看dataset 单条数据
  sample1 shape:((17, 97), <class 'numpy.ndarray'>) , Label:(1, <class 'numpy.int64'>)
  total data:5000,epochs:20,batch_size:32
  1 epoch has 157 steps
查看train_loader 容器数据
  total data 3008
  batch_size: 32
  Number of batches: 94
  type of batches: <class 'torch.utils.data.dataloader.DataLoader'>
input shape: torch.Size([32, 1, 17, 97])
input type: torch.FloatTensor
lable shape: torch.Size([32])
lable type: torch.LongTensor

自定义模型
torch.Size([32, 1, 17, 97])
++++++   start train  ++++++
+++++++  ----------  +++++++
[1 epoch, 31 step]:
accuracy: 0.7237903225806451 , loss: 0.6787152650856203
[1 epoch, 62 step]:
accuracy: 0.9586693548387096 , loss: 0.14692599458559866
[1 epoch, 93 step]:
accuracy: 0.9576612903225806 , loss: 0.12008409568619344
---------------- current_learn_rate ----------------- : 0.000100000000000
[2 epoch, 31 step]:
accuracy: 0.9635826771653543 , loss: 0.09747294919385065
[2 epoch, 62 step]:
accuracy: 0.9879032258064516 , loss: 0.046120276884926904
[2 epoch, 93 step]:
accuracy: 0.9727822580645161 , loss: 0.07450143401060373
---------------- current_learn_rate ----------------- : 0.000100000000000
[3 epoch, 31 step]:
accuracy: 0.9901574803149606 , loss: 0.04727296573260138
[3 epoch, 62 step]:
accuracy: 0.9929435483870968 , loss: 0.0308877328380702
[3 epoch, 93 step]:
accuracy: 0.9909274193548387 , loss: 0.029726579026769725
---------------- current_learn_rate ----------------- : 0.000100000000000
[4 epoch, 31 step]:
accuracy: 0.9911417322834646 , loss: 0.029841251776463563
[4 epoch, 62 step]:
accuracy: 0.9969758064516129 , loss: 0.019290325735064763
[4 epoch, 93 step]:
accuracy: 0.9909274193548387 , loss: 0.030637133408397917
---------------- current_learn_rate ----------------- : 0.000100000000000
[5 epoch, 31 step]:
accuracy: 0.9891732283464567 , loss: 0.024881836094502962
[5 epoch, 62 step]:
accuracy: 0.9969758064516129 , loss: 0.015202652328767843
[5 epoch, 93 step]:
accuracy: 0.9939516129032258 , loss: 0.018894160680863404
---------------- current_learn_rate ----------------- : 0.000100000000000
[6 epoch, 31 step]:
accuracy: 0.9980314960629921 , loss: 0.010153403227788306
[6 epoch, 62 step]:
accuracy: 0.9979838709677419 , loss: 0.008228427093971761
[6 epoch, 93 step]:
accuracy: 0.9959677419354839 , loss: 0.012599754659834528
---------------- current_learn_rate ----------------- : 0.000100000000000
[7 epoch, 31 step]:
accuracy: 0.9901574803149606 , loss: 0.028837862375733114
[7 epoch, 62 step]:
accuracy: 0.9949596774193549 , loss: 0.0131182107819064
[7 epoch, 93 step]:
accuracy: 0.9979838709677419 , loss: 0.008312331426197724
---------------- current_learn_rate ----------------- : 0.000100000000000
[8 epoch, 31 step]:
accuracy: 0.9940944881889764 , loss: 0.016310498591572527
[8 epoch, 62 step]:
accuracy: 0.9949596774193549 , loss: 0.017450847080908716
[8 epoch, 93 step]:
accuracy: 0.9959677419354839 , loss: 0.011705915278364573
---------------- current_learn_rate ----------------- : 0.000100000000000
[9 epoch, 31 step]:
accuracy: 1.0 , loss: 0.004440615992925521
[9 epoch, 62 step]:
accuracy: 0.998991935483871 , loss: 0.004421433889224465
[9 epoch, 93 step]:
accuracy: 0.998991935483871 , loss: 0.004846093758392418
---------------- current_learn_rate ----------------- : 0.000100000000000
[10 epoch, 31 step]:
accuracy: 1.0 , loss: 0.004017012861309453
[10 epoch, 62 step]:
accuracy: 0.998991935483871 , loss: 0.004074604733989785
[10 epoch, 93 step]:
accuracy: 0.9969758064516129 , loss: 0.008505105775604475
---------------- current_learn_rate ----------------- : 0.000100000000000
[11 epoch, 31 step]:
accuracy: 0.9980314960629921 , loss: 0.006219762897554545
[11 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0026339105369838616
[11 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0021702820602278678
---------------- current_learn_rate ----------------- : 0.000100000000000
[12 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0022902048513060436
[12 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0009115043287766316
[12 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0007197753612643048
---------------- current_learn_rate ----------------- : 0.000100000000000
[13 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0011395689509827794
[13 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0006122566447893698
[13 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003609420415276902
---------------- current_learn_rate ----------------- : 0.000010000000000
[14 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0005939797239637212
[14 epoch, 62 step]:
accuracy: 1.0 , loss: 0.000456731089094143
[14 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003302765959937636
---------------- current_learn_rate ----------------- : 0.000010000000000
[15 epoch, 31 step]:
accuracy: 1.0 , loss: 0.000514685757215991
[15 epoch, 62 step]:
accuracy: 1.0 , loss: 0.000401757504967522
[15 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003135724701062446
---------------- current_learn_rate ----------------- : 0.000010000000000
[16 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00046746724511913566
[16 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003696614909248667
[16 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00030219561731134874
---------------- current_learn_rate ----------------- : 0.000010000000000
[17 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0004345193876595717
[17 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003474154765436035
[17 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002936517292607365
---------------- current_learn_rate ----------------- : 0.000010000000000
[18 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00040974531657411717
[18 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003305548457466366
[18 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002864740505878393
---------------- current_learn_rate ----------------- : 0.000010000000000
[19 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00038970745980247646
[19 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00031688073349575845
[19 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002798993478908444
---------------- current_learn_rate ----------------- : 0.000010000000000
[20 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00037300781097597324
[20 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003051740265706734
[20 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002736172670753853
---------------- current_learn_rate ----------------- : 0.000010000000000
total_time:1.0332827687263488min
Finished Training
++++++++  start test  +++++++
++++++++  ----------  +++++++
Accuracy of the network on the 1987/2000 tests: 99.35 %
[382.0, 413.0, 383.0, 415.0, 407.0]

Accuracy of normal : 100.00 %
Accuracy of broken : 98.55 %
Accuracy of missing_tooth : 98.17 %
Accuracy of root_crack : 100.00 %
Accuracy of  wear : 100.00 %

2channel STFT

当前日期和时间: 2025-02-17 17:50:22.652322
  1_using cuda:0 device.
查看dataset 单条数据
  sample1 shape:((128, 1536), <class 'numpy.ndarray'>) , Label:(1, <class 'numpy.int64'>)
  total data:5000,epochs:20,batch_size:32
  1 epoch has 157 steps
查看train_loader 容器数据
  total data 3008
  batch_size: 32
  Number of batches: 94
  type of batches: <class 'torch.utils.data.dataloader.DataLoader'>
input shape: torch.Size([32, 1, 128, 1536])
input type: torch.FloatTensor
lable shape: torch.Size([32])
lable type: torch.LongTensor

自定义模型
torch.Size([32, 1, 128, 1536])
++++++   start train  ++++++
+++++++  ----------  +++++++
[1 epoch, 31 step]:
accuracy: 0.7116935483870968 , loss: 0.7447802107180318
[1 epoch, 62 step]:
accuracy: 0.9082661290322581 , loss: 0.26251841408591114
[1 epoch, 93 step]:
accuracy: 0.9112903225806451 , loss: 0.22188101059967472
---------------- current_learn_rate ----------------- : 0.000100000000000
[2 epoch, 31 step]:
accuracy: 0.9458661417322834 , loss: 0.1485484266473401
[2 epoch, 62 step]:
accuracy: 0.969758064516129 , loss: 0.08478342092806293
[2 epoch, 93 step]:
accuracy: 0.9747983870967742 , loss: 0.07859770563100615
---------------- current_learn_rate ----------------- : 0.000100000000000
[3 epoch, 31 step]:
accuracy: 0.985236220472441 , loss: 0.060627108319632465
[3 epoch, 62 step]:
accuracy: 0.9899193548387096 , loss: 0.035443113681169286
[3 epoch, 93 step]:
accuracy: 0.9949596774193549 , loss: 0.027992130399891926
---------------- current_learn_rate ----------------- : 0.000100000000000
[4 epoch, 31 step]:
accuracy: 0.9950787401574803 , loss: 0.023592257369009238
[4 epoch, 62 step]:
accuracy: 0.998991935483871 , loss: 0.009252603984467925
[4 epoch, 93 step]:
accuracy: 0.9969758064516129 , loss: 0.011540580060212843
---------------- current_learn_rate ----------------- : 0.000100000000000
[5 epoch, 31 step]:
accuracy: 0.9970472440944882 , loss: 0.012136614276847292
[5 epoch, 62 step]:
accuracy: 0.9969758064516129 , loss: 0.02146851032176205
[5 epoch, 93 step]:
accuracy: 0.9969758064516129 , loss: 0.012666756061897162
---------------- current_learn_rate ----------------- : 0.000100000000000
[6 epoch, 31 step]:
accuracy: 0.9990157480314961 , loss: 0.008294558477392721
[6 epoch, 62 step]:
accuracy: 0.998991935483871 , loss: 0.005277186113920423
[6 epoch, 93 step]:
accuracy: 0.998991935483871 , loss: 0.00603855800469436
---------------- current_learn_rate ----------------- : 0.000100000000000
[7 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0031548691509787233
[7 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0022314287113746807
[7 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0016655453815004758
---------------- current_learn_rate ----------------- : 0.000100000000000
[8 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0013937033579549602
[8 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0009997908782679588
[8 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0008494350148530136
---------------- current_learn_rate ----------------- : 0.000100000000000
[9 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0007137947996530021
[9 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0007360801006847571
[9 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0006033215073740951
---------------- current_learn_rate ----------------- : 0.000100000000000
[10 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0005660785348980778
[10 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0005814682588078863
[10 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00048514524232521055
---------------- current_learn_rate ----------------- : 0.000100000000000
[11 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00047358901628608544
[11 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0004844944609606999
[11 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0004110531698379125
---------------- current_learn_rate ----------------- : 0.000100000000000
[12 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0004077927461044202
[12 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00041513151870364504
[12 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003565295731776484
---------------- current_learn_rate ----------------- : 0.000100000000000
[13 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003598895622886747
[13 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00036090138347654214
[13 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00032076682339632703
---------------- current_learn_rate ----------------- : 0.000010000000000
[14 epoch, 31 step]:
accuracy: 1.0 , loss: 0.000354759763614575
[14 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00035575730209764573
[14 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003172092317160399
---------------- current_learn_rate ----------------- : 0.000010000000000
[15 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00034959137912899736
[15 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00035072674208711234
[15 epoch, 93 step]:
accuracy: 1.0 , loss: 0.000313518091007286
---------------- current_learn_rate ----------------- : 0.000010000000000
[16 epoch, 31 step]:
accuracy: 1.0 , loss: 0.0003444438221894445
[16 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00034572677771305485
[16 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00030950001359263796
---------------- current_learn_rate ----------------- : 0.000010000000000
[17 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00033930168231768957
[17 epoch, 62 step]:
accuracy: 1.0 , loss: 0.0003407529528034971
[17 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00030543438028431526
---------------- current_learn_rate ----------------- : 0.000010000000000
[18 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00033395508592460124
[18 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00033562414718025753
[18 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0003011446948925544
---------------- current_learn_rate ----------------- : 0.000010000000000
[19 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00032869509196907824
[19 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00033046067232311133
[19 epoch, 93 step]:
accuracy: 1.0 , loss: 0.0002966601823573001
---------------- current_learn_rate ----------------- : 0.000010000000000
[20 epoch, 31 step]:
accuracy: 1.0 , loss: 0.00032331835738601044
[20 epoch, 62 step]:
accuracy: 1.0 , loss: 0.00032519818764300114
[20 epoch, 93 step]:
accuracy: 1.0 , loss: 0.00029214419567236496
---------------- current_learn_rate ----------------- : 0.000010000000000
total_time:1.2993631879488627min
Finished Training
++++++++  start test  +++++++
++++++++  ----------  +++++++
Accuracy of the network on the 1968/2000 tests: 98.40 %
[382.0, 413.0, 383.0, 415.0, 407.0]

Accuracy of normal : 100.00 %
Accuracy of broken : 94.92 %
Accuracy of missing_tooth : 98.43 %
Accuracy of root_crack : 100.00 %
Accuracy of  wear : 98.77 %

WAVELET 2channel